{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply Chain tree for OpenX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validators\n",
    "from collections import deque\n",
    "import urllib.request, json \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sellers.json is a specification createtd to increase trust of the suplly chain. \n",
    "\n",
    "More information can be found at: https://iabtechlab.com/wp-content/uploads/2019/07/Sellers.json_Final.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly it is not that easy to get the suply chain, because not all comapnies share sellers.json file. And some companies share it, but not in proper way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problematic websites\n",
    "https://www.ntvbmedia.com/sellers.json no domain key\n",
    "\n",
    "https://didna.io/sellers.json - infinite lop\n",
    "\n",
    "https://streamlyn.com/sellers.json - says that sidonews is INTERMEDIARY\n",
    "\n",
    "https://www.sindonews.com/sellers.json - do not have any sellers\n",
    "\n",
    "pmc.com -> https://ads.shemedia.com/sellers.json - no domain\n",
    "\n",
    "https://adtelligent.com/sellers.json - domain starts with https://"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple function that would allow us to traverse suply chainand store data as python dictionary would look like this. I would be a better approach to create class (structure) and then store information about variables in it. There are some limitations in this function. Every signle website would be accesed only once, so if there are multiple sellers sharing data at the same website we would need to give them the same \"pointer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes(url,urls=None):\n",
    "    if urls is None:\n",
    "        urls = []\n",
    "    urls.append(url)\n",
    "    if url.startswith('http://www.'):\n",
    "        seller_url= 'http://' + url[len('http://www.'):]\n",
    "    if url.startswith('www.'):\n",
    "        seller_url= 'http://' + url[len('www.'):]\n",
    "    if not url.startswith('http://'):\n",
    "        seller_url= 'http://' + url\n",
    "    else:\n",
    "        seller_url = url\n",
    "    if seller_url.endswith(\"/\"):\n",
    "        seller_url += \"sellers.json\"\n",
    "    else:\n",
    "        seller_url += \"/sellers.json\"\n",
    "\n",
    "    try:\n",
    "        with urllib.request.urlopen(seller_url) as url:\n",
    "            # print(seller_url)\n",
    "            data = json.loads(url.read().decode())\n",
    "    except:\n",
    "        return None\n",
    "    if \"sellers\" in data.keys():\n",
    "        for idx,elem in enumerate(data[\"sellers\"]):\n",
    "            if \"seller_type\" in elem.keys():\n",
    "                if elem[\"seller_type\"] in [\"INTERMEDIARY\", \"BOTH\"] and \"domain\" in elem.keys():\n",
    "                    if validators.url(seller_url):\n",
    "                        if (elem[\"domain\"] not in urls):\n",
    "                            data[\"sellers\"][idx][\"sellers_kids\"] = get_nodes(elem[\"domain\"],urls)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have let this run for several hours, and it was always blocked at https://www.newsy.com/sellers.json\n",
    "openx_url = \"openx.com\"\n",
    "data = get_nodes (openx_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With this code we would be able to get the depth of suplly chain, assuming all comapnies are using sellers.json properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth(d):\n",
    "    queue = deque([(id(d), d, 1)])\n",
    "    memo = set()\n",
    "    while queue:\n",
    "        id_, o, level = queue.popleft()\n",
    "        if id_ in memo:\n",
    "            continue\n",
    "        memo.add(id_)\n",
    "        if isinstance(o, dict):\n",
    "            queue += ((id(v), v, level + 1) for v in o.values())\n",
    "    return level\n",
    "\n",
    "lvl = depth(data)\n",
    "print(lvl)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7857eea2c1caef8a8ccaef7161b842466cc3b0399d934f90918ce1af6b1741f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ABD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
